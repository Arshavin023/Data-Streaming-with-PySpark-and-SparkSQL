## data_pipeline_delta_live_tables_-PySpark

#### This project leveraged Delta Live Tables (DLT) and Python (PySpark) to construct a robust data pipeline within a Jupyter Notebook. The workflow encompassed the ingestion of customer and loan_applications data from Azure Blob storage, creation of Delta Live Tables and processing of data at bronze, silver, and gold layers, configuration the DLT pipeline, and scheduling of the DLT pipeline for seamless automation.
